{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8e1f8f4",
   "metadata": {},
   "source": [
    "### 1. Computing Wasserstein-1 distance between Q and steady state of M/M/1 queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3257c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad99ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def W1_MM1(q: list, a: list, rho: float, padding: int = 100, tolerance: float = 1e-9):\n",
    "    \"\"\"\n",
    "    Computes the 1-Wasserstein distance between an empirical distribution Q\n",
    "    and the theoretical M/M/1 steady-state distribution X, using rho directly.\n",
    "\n",
    "    The theoretical distribution X is truncated at a point determined by both\n",
    "    a padding value beyond the empirical support and a tolerance for the\n",
    "    tail mass.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : list or np.ndarray\n",
    "        Probability weights of the empirical distribution Q.\n",
    "    a : list or np.ndarray\n",
    "        Support points of Q, corresponding to q.\n",
    "    rho : float\n",
    "        The traffic intensity (lambda / mu) of the M/M/1 queue. Must be in [0, 1).\n",
    "    padding : int, optional\n",
    "        The support for the calculation will extend at least this many points\n",
    "        beyond the maximum support point of Q. Default is 10.\n",
    "    tolerance : float, optional\n",
    "        The tail mass of the truncated theoretical distribution will be less\n",
    "        than this value. Default is 1e-9.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed 1-Wasserstein distance.\n",
    "    \"\"\"\n",
    "    # --- 1. Input Validation and Parameter Setup ---\n",
    "    if not (0 <= rho < 1):\n",
    "        raise ValueError(\"Traffic intensity rho must be in the range [0, 1).\")\n",
    "    \n",
    "    # --- 2. Determine the Truncation Point for the Distributions ---\n",
    "    # The final support will be [0, 1, ..., max_k]\n",
    "    \n",
    "    # Condition 1: Truncate based on padding\n",
    "    max_a = max(a) if len(a) > 0 else 0\n",
    "    trunc_point_padding = max_a + padding\n",
    "    \n",
    "    # Condition 2: Truncate based on tail mass tolerance\n",
    "    # We need to find N such that rho**(N+1) < tolerance\n",
    "    if rho > 0:\n",
    "        # (N+1) * log(rho) < log(tolerance) => N+1 > log(tolerance) / log(rho) (log(rho) is negative)\n",
    "        trunc_point_tol = math.ceil(math.log(tolerance) / math.log(rho)) - 1\n",
    "    else: # if rho is 0, the distribution is just P(0)=1\n",
    "        trunc_point_tol = 0\n",
    "\n",
    "    # The final truncation point is the larger of the two\n",
    "    max_k = max(trunc_point_padding, trunc_point_tol)\n",
    "    \n",
    "    # The common support for both distributions\n",
    "    support = np.arange(max_k + 1)\n",
    "    \n",
    "    # --- 3. Construct the Full PMF for the Empirical Distribution Q ---\n",
    "    emp_weights = np.zeros(max_k + 1)\n",
    "    for i in range(len(a)):\n",
    "        if a[i] <= max_k:\n",
    "            emp_weights[a[i]] = q[i]\n",
    "            \n",
    "    # Normalize just in case the original q was not normalized\n",
    "    if emp_weights.sum() > 0:\n",
    "        emp_weights /= emp_weights.sum()\n",
    "\n",
    "    # --- 4. Construct the Full PMF for the Theoretical Distribution X ---\n",
    "    # Calculate the geometric distribution probabilities\n",
    "    th_weights = (1 - rho) * (rho ** support)\n",
    "    \n",
    "    # The tail mass is everything from max_k + 1 onwards.\n",
    "    # For a geometric distribution, this sum is exactly rho**(max_k + 1)\n",
    "    tail_mass = rho**(max_k + 1)\n",
    "    \n",
    "    # Add the tail mass to the last point to ensure the distribution sums to 1\n",
    "    th_weights[max_k] += tail_mass\n",
    "    \n",
    "    # --- 5. Compute and Return the Wasserstein Distance ---\n",
    "    return wasserstein_distance(support, support, u_weights=emp_weights, v_weights=th_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f869a04",
   "metadata": {},
   "source": [
    "### 2. Stein Discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91aaecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c702fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SD_MM1_V1(q: list, a: list, lmd: float, mu: float):\n",
    "    \"\"\"\n",
    "    Computes the W1 distance by solving a robust, sparse Linear Program.\n",
    "\n",
    "    This version explicitly defines variables for both the slope (x_k) and\n",
    "    the curvature (y_k) for maximum clarity and theoretical soundness.\n",
    "    It handles unsorted input and ensures 0 and 1 are in the support.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : list or np.ndarray\n",
    "        Probability weights corresponding to 'a'.\n",
    "    a : list or np.ndarray\n",
    "        Support points. Does not need to be sorted.\n",
    "    lmd : float\n",
    "        Arrival rate for the M/M/1 queue.\n",
    "    mu : float\n",
    "        Service rate for the M/M/1 queue.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj_val : float or None\n",
    "        The optimal objective value (the W1 distance). None if not optimal.\n",
    "    status : str\n",
    "        The human-readable Gurobi solver status.\n",
    "    \"\"\"\n",
    "    # --- 1. Input Validation & Data Pre-processing ---\n",
    "    if len(q) != len(a):\n",
    "        raise ValueError(\"Length of weights q and support a must be equal.\")\n",
    "    if mu <= lmd:\n",
    "        raise ValueError(\"Service rate mu must be greater than arrival rate lmd.\")\n",
    "\n",
    "    point_map = {k: v for k, v in zip(a, q)}\n",
    "    point_map.setdefault(0, 0.0)\n",
    "    point_map.setdefault(1, 0.0)\n",
    "\n",
    "    sorted_points = sorted(point_map.items())\n",
    "    a = [point[0] for point in sorted_points]\n",
    "    q = [point[1] for point in sorted_points]\n",
    "    \n",
    "    stability_bound_C = 1.0 / (mu - lmd)\n",
    "\n",
    "    # --- 2. Identify all necessary \"Critical Points\" ---\n",
    "    critical_points_base = set()\n",
    "    for point in a:\n",
    "        critical_points_base.add(point)\n",
    "        if point > 0:\n",
    "            critical_points_base.add(point - 1)\n",
    "    \n",
    "    if not critical_points_base:\n",
    "        critical_points_base.add(0)\n",
    "\n",
    "    # max_base_point = max(critical_points_base)\n",
    "    # critical_points_x = critical_points_base.union({max_base_point + 1})\n",
    "    critical_points_x = critical_points_base\n",
    "\n",
    "    K_x = sorted(list(critical_points_x))\n",
    "    print(K_x)\n",
    "    p_x = len(K_x)\n",
    "    x_point_to_idx = {k: j for j, k in enumerate(K_x)}\n",
    "\n",
    "    K_y = [k for k in K_x if k + 1 in x_point_to_idx]\n",
    "    p_y = len(K_y)\n",
    "    y_point_to_idx = {k: j for j, k in enumerate(K_y)}\n",
    "    print(y_point_to_idx)\n",
    "    \n",
    "    # --- 3. Build the Gurobi LP Model ---\n",
    "    model = gp.Model(\"SD_MM1_V1\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    \n",
    "    # --- 4. Define EXPLICIT Variables for x_k and y_k ---\n",
    "    x = model.addVars(p_x, lb=-GRB.INFINITY, name=\"x\")\n",
    "    y = model.addVars(p_y, lb=-GRB.INFINITY, name=\"y\")\n",
    "\n",
    "    # --- 5. Set the Objective Function ---\n",
    "    obj_expr = 0\n",
    "    for i in range(len(a)):\n",
    "        a_i, q_i = a[i], q[i]\n",
    "        if q_i == 0: continue\n",
    "        \n",
    "        idx_ai = x_point_to_idx[a_i]\n",
    "        obj_expr += q_i * lmd * x[idx_ai]\n",
    "        \n",
    "        if a_i > 0:\n",
    "            idx_ai_minus_1 = x_point_to_idx[a_i - 1]\n",
    "            obj_expr += q_i * (-mu) * x[idx_ai_minus_1]\n",
    "            \n",
    "    model.setObjective(obj_expr, GRB.MAXIMIZE)\n",
    "\n",
    "    # --- 6. Set ALL Constraints Explicitly ---\n",
    "\n",
    "    # 6a. Consistency Constraint: y_k = x_{k+1} - x_k\n",
    "    for k_y_val, j_y in y_point_to_idx.items():\n",
    "        j_x_curr = x_point_to_idx[k_y_val]\n",
    "        j_x_next = x_point_to_idx[k_y_val + 1]\n",
    "        model.addConstr(y[j_y] == x[j_x_next] - x[j_x_curr])\n",
    "\n",
    "    # 6b. Stability Constraint: |y_k| <= C\n",
    "    for j_y in range(p_y):\n",
    "        model.addConstr(y[j_y] <= stability_bound_C)\n",
    "        model.addConstr(y[j_y] >= -stability_bound_C)\n",
    "\n",
    "    # 6c. Lipschitz-on-Generator Constraint: |lambda*y_k - mu*y_{k-1}| <= 1\n",
    "    idx_y0 = y_point_to_idx[0]\n",
    "    idx_x0 = x_point_to_idx[0]\n",
    "    expr_init = lmd * y[idx_y0] - mu * x[idx_x0]\n",
    "    model.addConstr(expr_init <= 1)\n",
    "    model.addConstr(expr_init >= -1)\n",
    "    \n",
    "    for k_y_val, j_y_curr in y_point_to_idx.items():\n",
    "        if k_y_val > 0 and (k_y_val - 1) in y_point_to_idx:\n",
    "            j_y_prev = y_point_to_idx[k_y_val - 1]\n",
    "            expr = lmd * y[j_y_curr] - mu * y[j_y_prev]\n",
    "            model.addConstr(expr <= 1)\n",
    "            model.addConstr(expr >= -1)\n",
    "\n",
    "    # --- 7. Solve and Return ---\n",
    "    model.optimize()\n",
    "    \n",
    "    # FIX: Map Gurobi status code to a human-readable string\n",
    "    status_code = model.Status\n",
    "    status_map = {\n",
    "        GRB.OPTIMAL: \"OPTIMAL\",\n",
    "        GRB.UNBOUNDED: \"UNBOUNDED\",\n",
    "        GRB.INFEASIBLE: \"INFEASIBLE\",\n",
    "        GRB.INF_OR_UNBD: \"INF_OR_UNBOUNDED\",\n",
    "        GRB.TIME_LIMIT: \"TIME_LIMIT\",\n",
    "    }\n",
    "    status = status_map.get(status_code, f\"UNKNOWN_STATUS_{status_code}\")\n",
    "    \n",
    "    obj_val = -1\n",
    "    if status_code == GRB.OPTIMAL:\n",
    "        obj_val = model.ObjVal\n",
    "        \n",
    "    return obj_val, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4b8fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with Parameters: lambda=0.7, mu=1.0 (rho=0.70)\n",
      "============================================================\n",
      "\n",
      "--- Test Case 1: Dense Distribution ---\n",
      "Support a = [0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3}\n",
      "  SD_MM1_V1 (LP Solver) Result: 1.05333333 (Status: OPTIMAL)\n",
      "  W1_MM1 (Scipy) Result:      1.05333333\n",
      "  Absolute Difference:          0.00000000\n",
      "\n",
      "--- Test Case 2: Sparse Distribution ---\n",
      "Support a = [0, 1, 100, 101]\n",
      "[0, 1, 99, 100, 101]\n",
      "{0: 0, 99: 1, 100: 2}\n",
      "  SD_MM1_V1 (LP Solver) Result: -1.00000000 (Status: INF_OR_UNBOUNDED)\n",
      "  W1_MM1 (Scipy) Result:      28.83266667\n",
      "  Absolute Difference:          29.83266667\n"
     ]
    }
   ],
   "source": [
    "# --- Shared Parameters ---\n",
    "lmd_val = 0.7\n",
    "mu_val = 1.0\n",
    "rho_val = lmd_val / mu_val\n",
    "\n",
    "print(f\"Testing with Parameters: lambda={lmd_val}, mu={mu_val} (rho={rho_val:.2f})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- Test Case 1: Dense Distribution ---\n",
    "print(\"\\n--- Test Case 1: Dense Distribution ---\")\n",
    "a_dense = [0, 1, 2, 3, 4]\n",
    "q_dense = np.array([0.1, 0.4, 0.3, 0.1, 0.1])\n",
    "q_dense /= q_dense.sum()\n",
    "print(f\"Support a = {a_dense}\")\n",
    "\n",
    "# Calculate using our sparse LP\n",
    "lp_val_dense, status_dense = SD_MM1_V1(q_dense, a_dense, lmd_val, mu_val)\n",
    "print(f\"  SD_MM1_V1 (LP Solver) Result: {lp_val_dense:.8f} (Status: {status_dense})\")\n",
    "\n",
    "# Calculate using standard library\n",
    "w1_val_dense = W1_MM1(q_dense, a_dense, rho_val)\n",
    "print(f\"  W1_MM1 (Scipy) Result:      {w1_val_dense:.8f}\")\n",
    "\n",
    "# Compare results\n",
    "if lp_val_dense is not None:\n",
    "    diff_dense = abs(lp_val_dense - w1_val_dense)\n",
    "    print(f\"  Absolute Difference:          {diff_dense:.8f}\")\n",
    "\n",
    "\n",
    "# --- Test Case 2: Sparse Distribution with a large gap ---\n",
    "print(\"\\n--- Test Case 2: Sparse Distribution ---\")\n",
    "a_sparse = [0, 1, 100, 101]\n",
    "q_sparse = np.array([0.4, 0.3, 0.1, 0.2])\n",
    "q_sparse /= q_sparse.sum()\n",
    "print(f\"Support a = {a_sparse}\")\n",
    "\n",
    "# Calculate using our sparse LP\n",
    "lp_val_sparse, status_sparse = SD_MM1_V1(q_sparse, a_sparse, lmd_val, mu_val)\n",
    "print(f\"  SD_MM1_V1 (LP Solver) Result: {lp_val_sparse:.8f} (Status: {status_sparse})\")\n",
    "\n",
    "# Calculate using standard library\n",
    "w1_val_sparse = W1_MM1(q_sparse, a_sparse, rho_val)\n",
    "print(f\"  W1_MM1 (Scipy) Result:      {w1_val_sparse:.8f}\")\n",
    "\n",
    "# Compare results\n",
    "if lp_val_sparse is not None:\n",
    "    diff_sparse = abs(lp_val_sparse - w1_val_sparse)\n",
    "    print(f\"  Absolute Difference:          {diff_sparse:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbc357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
